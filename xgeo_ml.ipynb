{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from collections import OrderedDict\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dateutil import parser\n",
    "from netCDF4 import Dataset, netcdftime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sol_and_sin = True\n",
    "base_url = 'http://h-web01.nve.no/chartserver/ShowData.aspx?req=getchart&ver=1.0&vfmt=json&time={time}&chd=ds=hgts,id={id};{url_id}'\n",
    "FIELDS = [\n",
    "    ('tmgr', 'temperaturendring'),\n",
    "    ('tm', 'temperatur'),\n",
    "    ('rr', 'nedbÃ¸r'),\n",
    "    ('gwb_eva', 'fordampning'),\n",
    "    ('gwb_sssrel', 'vannmetning_i_jord'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgeo_get_id(point: dict) -> str:\n",
    "    \"\"\"retruns formated id used in base_url\"\"\"\n",
    "    return f\"{point['x']};{point['y']}\"\n",
    "\n",
    "\n",
    "def xgeo_get_time(point: dict, days_back: int=2) -> str:\n",
    "    \"\"\"return formated time used in the base_url\"\"\"\n",
    "    time_delta = datetime.timedelta(days=days_back)\n",
    "    time_to = parser.parse(point['time'], dayfirst=False)\n",
    "    time_from = time_to - time_delta\n",
    "    return f\"{time_from.strftime('%Y%m%dT0000')};{time_to.strftime('%Y%m%dT0000')}\"\n",
    "\n",
    "\n",
    "def xgeo_get_values (point: dict) -> [dict, bool]:\n",
    "    \"\"\"\n",
    "    takes a point as input and loops throug the FIELDS and collects the data\n",
    "    for the point from xgeo\n",
    "\n",
    "    retruns point or False if failed\n",
    "    \"\"\"\n",
    "    for field_id, field_name in FIELDS:\n",
    "        url = base_url.format(time=xgeo_get_time(point), id=xgeo_get_id(point), url_id=field_id)\n",
    "        r = requests.get(url).json()\n",
    "        if len(r[0]['SeriesPoints']) == 0:\n",
    "            return False\n",
    "        # sleep(1)  # takes to long\n",
    "        if r[0]['SeriesPoints'][2]['Value'] is None:\n",
    "            return False\n",
    "        point[f'{field_name}_days_back_0'] = r[0]['SeriesPoints'][2]['Value']\n",
    "        point[f'{field_name}_days_back_1'] = r[0]['SeriesPoints'][1]['Value']\n",
    "        point[f'{field_name}_days_back_2'] = r[0]['SeriesPoints'][0]['Value']\n",
    "    return point\n",
    "\n",
    "\n",
    "def xgeo_create_false_data(point: dict) -> list:\n",
    "    \"\"\"\n",
    "    takes a point as input and creates 3 ekstra points in the same location\n",
    "    but different time, and collects the xgeo data\n",
    "\n",
    "    returns list with the new points\n",
    "    \"\"\"\n",
    "    false_points = []\n",
    "    for i in [-1, 1]:\n",
    "        time_delta = datetime.timedelta(days=(10*i))\n",
    "        false_point = OrderedDict()\n",
    "        false_point['x'] = point['x']\n",
    "        false_point['y'] = point['y']\n",
    "        false_point['FID'] = point['FID'] + f\"_{i}\"\n",
    "        false_point['time'] = (parser.parse(point['time'], dayfirst=False) + time_delta).strftime('%Y-%m-%d 00:00:00')\n",
    "        false_point['solslyng'] = False\n",
    "        if sol_and_sin:\n",
    "            false_point['sol_rad'] = point['sol_rad']\n",
    "            false_point['sin'] = point['sin']\n",
    "        false_point = xgeo_get_values(false_point)\n",
    "        if false_point:\n",
    "            false_points.append(false_point)\n",
    "    return false_points\n",
    "\n",
    "\n",
    "def xgeo_create_points_from_csv(path_to_csv):\n",
    "    points = []\n",
    "    with open(path_to_csv, newline='') as f:\n",
    "        for row in csv.reader(f, delimiter=';'):\n",
    "            if row[0] == 'XCoord':\n",
    "                continue\n",
    "            point = OrderedDict()\n",
    "            point['x'] = row[0].replace(',', '.')\n",
    "            point['y'] = row[1].replace(',', '.')\n",
    "            point['FID'] = row[2]\n",
    "            point['time'] = parser.parse(row[3], dayfirst=True).strftime('%Y-%m-%d 00:00:00')\n",
    "            point['solslyng'] = True #int(row[-1])\n",
    "            point['sol_rad'] = float(row[4].replace(',', '.'))\n",
    "            point['sin'] = float(row[5].replace(',', '.'))\n",
    "            point = xgeo_get_values(point)\n",
    "            if not point is False:\n",
    "                points.append(point)\n",
    "                points += xgeo_create_false_data(point) if point['solslyng'] else []\n",
    "    return points\n",
    "\n",
    "\n",
    "def xgeo_create_x_y(points: list):\n",
    "    \"\"\"creates X data, and Y label to be used in SVC\"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    for point in points:\n",
    "        X.append(list(point.values())[5:])  # attributes\n",
    "        Y.append(int(list(point.values())[4]))  # solslyng false or true\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_csv =  r'C:\\Users\\student\\Desktop\\python\\xgeo\\solslyng_p_mb_m_s_r.csv'\n",
    "p = xgeo_create_points_from_csv(path_to_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgeo_X, xgeo_y = xgeo_create_x_y(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_svc(X, y):\n",
    "    \"\"\"Elise template :) creates the svc model\"\"\"\n",
    "    pipe = make_pipeline(StandardScaler(), SVC())\n",
    "    param_c = np.logspace(-4, 4)\n",
    "    param_gamma = np.logspace(-4, 4)\n",
    "    param_grid = [\n",
    "        {\n",
    "            'svc__C': param_c,\n",
    "            'svc__gamma': param_gamma,\n",
    "            'svc__kernel': ['rbf'],\n",
    "            'svc__random_state': [1],\n",
    "            'svc__probability': [True],\n",
    "            #'pca__n_components': [2, 8, 16]\n",
    "        }\n",
    "    ]\n",
    "    gs = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=10,\n",
    "        n_jobs=7\n",
    "    )\n",
    "    gs = gs.fit(X, y)\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = train_svc(xgeo_X, xgeo_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([_x + [_y] for _x, _y in zip(xgeo_X, xgeo_y)])\n",
    "corr = df.corr().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read from csv an creat predicet point\n",
    "def xgeo_create_predict_points_from_csv(path_to_csv, predict_date):\n",
    "    points = []\n",
    "    with open(path_to_csv, newline='') as f:\n",
    "        for i, row in enumerate(csv.reader(f, delimiter=';')):\n",
    "            print(i)\n",
    "            if row[0] == 'XCoord':\n",
    "                continue\n",
    "            point = OrderedDict()\n",
    "            try:\n",
    "                point['x'] = row[0].replace(',', '.')\n",
    "                point['y'] = row[1].replace(',', '.')\n",
    "                point['FID'] = row[2]\n",
    "                point['time'] = parser.parse(predict_date, dayfirst=True).strftime('%Y-%m-%d 00:00:00')\n",
    "                point['solslyng'] = None\n",
    "                point['sol_rad'] = float(row[3].replace(',', '.'))\n",
    "                point['sin'] = float(row[4].replace(',', '.'))\n",
    "                point = xgeo_get_values(point)\n",
    "                if not point is False:\n",
    "                    points.append(point)\n",
    "            except:\n",
    "                continue\n",
    "    return points\n",
    "\n",
    "\n",
    "def xgeo_create_X(points: list):\n",
    "    \"\"\"creates X data, to be used in prediction\"\"\"\n",
    "    X = []\n",
    "    for point in points:\n",
    "        X.append(list(point.values())[5:])  # attributes\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set prediction date\n",
    "date_str = '18.07.2015'  # SET\n",
    "path_to_predict_csv_hele_norge = r\"C:\\Users\\student\\Desktop\\python\\ml\\Hele_norge.csv\"\n",
    "predict_points_hele = xgeo_create_predict_points_from_csv(path_to_predict_csv_hele_norge, date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_X = xgeo_create_X(predict_points_hele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_y_ = p_gs.predict_proba(pred_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create point and proba csv\n",
    "\n",
    "with open('xgeo/proba_hele_11072015.csv', 'w') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for x_y, proba in zip([list(p.values()) for p in predict_points_hele], pred_y_):\n",
    "        writer.writerow([x_y[0], x_y[1], proba[1]])                \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
